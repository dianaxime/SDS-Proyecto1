{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b49c8766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import datasets\n",
    "# Import train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5bd538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "X_train = pd.read_csv('x_train_smote_undersample.csv').to_numpy()\n",
    "y_train = pd.read_csv('y_train_smote_undersample.csv')\n",
    "y_train = y_train['LABEL']\n",
    "\n",
    "# Test data\n",
    "X_test = pd.read_csv('x_test_smote_undersample.csv').to_numpy()\n",
    "y_test = pd.read_csv('y_test_smote_undersample.csv')\n",
    "y_test = y_test['LABEL']\n",
    "\n",
    "# Validation data\n",
    "X_validation = pd.read_csv('x_validation_smote_undersample.csv').to_numpy()\n",
    "y_validation = pd.read_csv('y_validation_smote_undersample.csv')\n",
    "y_validation = y_validation['LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61109563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          1\n",
       "1          0\n",
       "2          1\n",
       "3          2\n",
       "4          0\n",
       "          ..\n",
       "1007144    0\n",
       "1007145    0\n",
       "1007146    0\n",
       "1007147    1\n",
       "1007148    3\n",
       "Name: LABEL, Length: 1007149, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abd745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=1)\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c9186a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "552095    0\n",
       "552096    0\n",
       "552097    0\n",
       "552098    0\n",
       "552099    0\n",
       "Name: LABEL, Length: 552100, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03a713b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.656143814526354\n"
     ]
    }
   ],
   "source": [
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae11c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusion [[249443  47186      0      0]\n",
      " [     5 112814      0      0]\n",
      " [103440      0      0      0]\n",
      " [ 39212      0      0      0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diana\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.84      0.72    296629\n",
      "           1       0.71      1.00      0.83    112819\n",
      "           2       0.00      0.00      0.00    103440\n",
      "           3       0.00      0.00      0.00     39212\n",
      "\n",
      "    accuracy                           0.66    552100\n",
      "   macro avg       0.34      0.46      0.39    552100\n",
      "weighted avg       0.49      0.66      0.56    552100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diana\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\diana\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Matriz de confusion', metrics.confusion_matrix(y_test, y_pred))\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=['0', '1', '2', '3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e384a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.97856879, 0.97857939, ..., 0.        , 0.        ,\n",
       "        0.9456797 ],\n",
       "       [0.        , 0.00736373, 0.00736381, ..., 0.        , 0.        ,\n",
       "        0.03339885],\n",
       "       [0.00103334, 0.96285116, 0.96286151, ..., 0.16294643, 0.        ,\n",
       "        0.9085013 ],\n",
       "       ...,\n",
       "       [0.00184168, 0.98103879, 0.98104927, ..., 0.        , 0.        ,\n",
       "        0.96227035],\n",
       "       [0.70139751, 0.98349279, 0.98345092, ..., 0.        , 0.        ,\n",
       "        0.9701839 ],\n",
       "       [0.        , 0.98428693, 0.98429759, ..., 0.15758929, 0.        ,\n",
       "        0.97260138]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11543ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics.plot_roc_curve(abc, X_test, y_test)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d48eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
